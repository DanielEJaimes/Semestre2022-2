# -*- coding: utf-8 -*-
"""Parcial2_FIA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jFp0141juSYSZdsxmRpqBV1yc5wkRTYl

* Daniel Enrique Patiño Jaimes 000421816
* David Santiago Velasco Daza 000430882
"""

pip install wfdb

"""Importaciones necesarias"""

import wfdb
import numpy as np
import matplotlib.pyplot as plt
import os
import pandas as pd
import statistics as stat
from scipy import stats as s
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split

"""1. Realizar un algoritmo que me permita identificar el latido cardiaco en una señal ECG utilizando patrones (características obtenidas de segmentos de la señal) utilizando como método o camino para ello redes neuronales artificiales (ANN).

Analizar la base de datos
"""

db = os.listdir('/content/database')
db.sort()
data=[]
signal=[]
for i in db:
  if i.__contains__(".atr"):
    data.append(i.replace(".atr",""))

print(data)

"""Extraer de las señales de cada registro"""

for i in data:
  record = wfdb.rdrecord('database/'+i)
  signal.append(record.p_signal[:,0])
  
print(signal)

"""Obtener posición de latidos y cantidad de latidos por registro"""

for i in data:
  annotation = wfdb.rdann('database/'+i,'atr').sample
  print(annotation) #Posiciones de latidos
  print(len(annotation)) #Cantidad de latidos

"""Agregar al dataset los registros con latidos y las características evaluadas (media, mediana, moda, desviación estándar y courtosis)"""

dataset = []
for i in data:
  annotation = wfdb.rdann('database/'+i,'atr').sample
  record = wfdb.rdrecord('database/'+i)
  signal = record.p_signal[:,0]
  cont = 0
  for j in annotation:
    if j > 8:
      if cont < 12000:
        frame = []
        Vobser = signal[j-7:j+7]
        media = (np.mean(Vobser))
        frame.append(media)
        moda = float(s.mode(Vobser)[0])
        frame.append(moda)
        mediana = (np.median(Vobser))
        frame.append(mediana)
        dev = (stat.pstdev(Vobser))
        frame.append(dev)
        kurt = (s.kurtosis(Vobser))
        frame.append(kurt)
        frame.append((1))
        dataset.append(frame)
      cont = cont + 1

"""Método de búsqueda binaria para hallar la posición de las señales que no son latidos"""

def busqueda_binaria(lista, valor):
    primero = 0
    ultimo = len(lista) - 1
    encontrado = False

    while primero <= ultimo and not encontrado:
        mitad = (primero + ultimo) // 2

        if lista[mitad] == valor:
            encontrado = True
        else:
            if valor < lista[mitad]:
                ultimo = mitad - 1
            else:
                primero = mitad + 1

    return encontrado

"""Agregar al dataset los registros sin latidos"""

for i in data:
  annotation = wfdb.rdann('database/'+i,'atr').sample
  record = wfdb.rdrecord('database/'+i)
  signal = record.p_signal[:,0]
  cont = 0
  for j in range(1,len(signal)+1):
    if j>8 and not(busqueda_binaria(annotation,j)):
      frame = []
      Vobser = signal[j-7:j+7]
      media = (np.mean(Vobser))
      frame.append(media)
      moda = float(s.mode(Vobser)[0])
      frame.append(moda)
      mediana = (np.median(Vobser))
      frame.append(mediana)
      dev = (stat.pstdev(Vobser))
      frame.append(dev)
      kurt = (s.kurtosis(Vobser))
      frame.append(kurt)
      frame.append(0)
      dataset.append(frame)
      cont = cont + 1
      if cont >= 12000:
        break

"""Generar el dataframe

"""

indices = ['Registro {}'.format(i) for i in range(1,len(dataset) + 1)]

df = pd.DataFrame(data = dataset, index = indices)

df.columns = ['Media','Moda','Mediana','Desviación','Courtosis','Latido']

df

"""Entrenar modelo"""

df_resultado = df[['Latido']]
df_caracteristica = df[['Media','Moda','Mediana','Desviación','Courtosis']]

x_train,x_test,y_train,y_test = train_test_split(df_caracteristica,df_resultado, test_size = 0.2) #test_size = porcentaje de datos para testear

clf = MLPClassifier(max_iter=200).fit(x_train,y_train)
clf.score(x_test,y_test)

"""**Conclusiones**
*    Al trabajar con una cantidad de datos tan grande, los tiempos de ejecución son bastante altos si no se busca una manera de optimizar el trabajo.
*    Se tuvo que realizar la implementación del método de búsqueda binario para identificar las posiciones que no tienen latido obteniendo una disminución bastante grande de tiempo.
*    Una correcta elección de las características puede facilitar el trabajo para el entrenamiento de la red neuronal.
*    Se obtuvo un desempeño aproximado de 93%
*    Las pruebas realizadas son los bloques de código en los que se extraen las señales y las anotaciones, después de identificar la manera de extraerlo se implementó el código con cantidades bajas de datos para comprobar su funcionamiento y posterior a eso se usó la cantidad completa de información.

2. Con las características de configuración de la red neuronal formada en el anterior segmento.
Aplicar dicha red sobre una ventana deslizante, graficar la salida de esta red y compararla con la señal de ECG.

Predicción de la red neuronal
*    Gráfica azul es ECG.
*    Gráfica naranja es la predicción.
"""

def recorrer(index):
  i = index
  iini = (i*14)-13
  ifin = (i*14)
  return i, iini, ifin

fig = plt.figure(figsize=(20,20))
fig.tight_layout()
cont = 0
for j in data:
  cont = cont+1
  diagramaResultado = []
  diagramaEsperado = []
  record = wfdb.rdrecord('database/'+j)
  signal = record.p_signal[:,0]
  for i in range (1,432001): #Recomendación: Definir el rango que se quiere graficar para obtener resultados más rápido
    index,posi,posf = recorrer(i)
    frame = []
    Vobser = signal[posi:posf]
    media = (np.mean(Vobser))
    frame.append(media)
    moda = float(s.mode(Vobser)[0])
    frame.append(moda)
    mediana = (np.median(Vobser))
    frame.append(mediana)
    dev = (stat.pstdev(Vobser))
    frame.append(dev)
    kurt = (s.kurtosis(Vobser))
    frame.append(kurt)
    frame = [frame] #Caracteríticas para hacer la predicción
    diagramaResultado.append(clf.predict(frame))
    diagramaEsperado.append(media)
  ax = plt.subplot(6,3,cont)
  ax.plot(diagramaEsperado[0:200]) #Señal de la base de datos
  ax.plot(diagramaResultado[0:200]) #Señal obtenida por la red neuronal
  ax.set_title('Registro: '+str(j))

"""**¿Qué problemas puedes observar usando únicamente la gráfica?**

*   Las frecuencias muy bajas son difíciles de predecir.
*   Cuando la señal no sufre de cambios drásticos los resultados pueden no tener coherencia (Registros 19088,19090,19093,19140,19830).

**¿Por qué se puede deber eso?**
*    Porque al entrenar la red neuronal con datos numéricos, un registro con frecuencias bajas puede llegarse a confundir a un resultado sin latido.
*    Los resultados sin coherencia pueden ser producto del tamaño de la ventana deslizante.

**Mencione una estrategia que puedas utilizar o implementar para mejorarlo.**
*    Agregar más características que permitan a la red neuronal identificar de mejor manera las bajas frecuencias.
*    Realizar pruebas y cambiar el tamaño de la ventana deslizante para identificar cambios positivos al ampliar o disminuir el tamaño.
"""